{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retreival  \n",
    "\n",
    "Created by : FrancoisHUP\n",
    "Last update : 20 dec 2023\n",
    "\n",
    "We are doing indexation on TREC AP 88-90 documents and querying the system with 150 requests.\n",
    "Then we check the MAP score. \n",
    "\n",
    "It create an index for each tokenisation methode.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AP880212-0001', 'Reports Former Saigon Officials Released from Re-education Camp', \"More than 150 former officers of the\\noverthrown South Vietnamese government have been released from a\\nre-education camp after 13 years of detention, the official Vietnam\\nNews Agency reported Saturday.\\n   The report from Hanoi, monitored in Bangkok, did not give\\nspecific figures, but said those freed Friday included an\\nex-Cabinet minister, a deputy minister, 10 generals, 115\\nfield-grade officers and 25 chaplains.\\n   It quoted Col. Luu Van Ham, director of the Nam Ha camp south of\\nHanoi, as saying all 700 former South Vietnamese officials who had\\nbeen held at the camp now have been released.\\n   They were among 1,014 South Vietnamese who were to be released\\nfrom re-education camps under an amnesty announced by the Communist\\ngovernment to mark Tet, the lunar new year that begins Feb. 17.\\n   The Vietnam News Agency report said many foreign journalists and\\na delegation from the Australia-Vietnam Friendship Association\\nattended the Nam Ha release ceremony.\\n   It said Lt. Gen. Nguyen Vinh Nghi, former commander of South\\nVietnam's Third Army Corps, and Col. Tran Duc Minh, former director\\nof the Army Infantry Officers School, expressed ``gratitude to the\\ngovernment for its humane treatment in spite of the fact that most\\nof them (detainees) had committed heinous crimes against the\\ncountry and people.''\\n   The prisoners had been held without formal charges or trial\\nsince North Vietnam defeated the U.S.-backed South Vietnamese\\ngovernment in April 1975, ending the Vietnam War.\\n   Communist authorities had called the prisoners war criminals and\\nsaid they had to learn how to become citizens of the new society.\\n   Small numbers had been released occasionally without publicity\\nbut the government announced last year that 480 political prisoners\\nwould be freed to mark National Day on Sept. 2.\\n   On Thursday, Vice Minister of Information Phan Quang said 1,014\\nwould be released under the Tet amnesty.\\n   He reported a total of 150 prisoners would remain in the camps,\\nwhich he said once held 100,000.\\n   ``Depending on their repentance, they will gradually be released\\nwithin a short period of time,'' Quang said.\\n   He said many of the former inmates would return to their\\nfamilies in Ho Chi Minh City, formerly the South Vietnamese capital\\nof Saigon.\\n   The amnesties apparently are part of efforts by Communist Party\\nchief Nguyen Van Linh to heal internal divisions and improve\\nVietnam's image abroad.\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "doc_pattern = re.compile(r'<DOC>(.*?)</DOC>', re.DOTALL)\n",
    "docno_pattern = re.compile(r'<DOCNO>\\s*(.*?)\\s*</DOCNO>')\n",
    "head_pattern = re.compile(r'<HEAD>\\s*(.*?)\\s*</HEAD>')\n",
    "text_pattern = re.compile(r'<TEXT>\\s*(.*?)\\s*</TEXT>', re.DOTALL)\n",
    "\n",
    "def get_documents() :\n",
    "    documents = []\n",
    "    # Get a list of all .gz files in the \"Ap\" directory\n",
    "    file_list = glob.glob('TREC AP 88-90/TREC AP 88-90/collection de documents/AP/*.gz') # start from ../src\n",
    "\n",
    "    # Loop over the list of files\n",
    "    for filename in file_list:\n",
    "        \n",
    "        # Open the .gz file\n",
    "        with gzip.open(filename, 'rt', encoding='latin1') as file:  # 'rt' mode for text reading\n",
    "            # Read the contents of the file\n",
    "            content = file.read()\n",
    "            for doc in doc_pattern.finditer(content):\n",
    "                doc_content = doc.group(1)\n",
    "\n",
    "                # Extracting individual elements\n",
    "                doc_id = docno_pattern.search(doc_content).group(1)\n",
    "                head = head_pattern.search(doc_content)\n",
    "                text = text_pattern.search(doc_content)\n",
    "                \n",
    "                documents.append([doc_id, head.group(1) if head else '',text.group(1) if text else ''])\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = get_documents()\n",
    "print(documents[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LUCENE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.document import Document, Field, StringField, TextField\n",
    "from org.apache.lucene.index import IndexWriter, IndexWriterConfig\n",
    "from org.apache.lucene.index import DirectoryReader\n",
    "from org.apache.lucene.store import MMapDirectory\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7ffa4183b1b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = StandardAnalyzer()\n",
    "analyzer = EnglishAnalyzer()\n",
    "index = MMapDirectory(Paths.get(\"indexStemming\"))  # specify a directory path\n",
    "config = IndexWriterConfig(analyzer)\n",
    "writer = IndexWriter(index, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    doc = Document()\n",
    "    doc.add(StringField(\"doc_id\", document[0], Field.Store.YES))  # Add your custom doc ID\n",
    "    doc.add(TextField(\"content\", document[1] + document[2], Field.Store.YES))\n",
    "    writer.addDocument(doc)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "topic_pattern = re.compile(r'<top>(.*?)</top>', re.DOTALL)\n",
    "# Regular expressions for individual elements\n",
    "num_pattern = re.compile(r'<num>\\s*Number:\\s*(\\d+)')\n",
    "title_pattern = re.compile(r'<title>\\s*Topic:\\s*(.*?)\\s*\\n')\n",
    "desc_pattern = re.compile(r'<desc>\\s*Description:\\s*(.*?)\\s*<narr>', re.DOTALL)\n",
    "\n",
    "def get_requests() :\n",
    "    requests = []\n",
    "    \n",
    "    # Get a list of all topics files in the \"Topics-requetes\" directory\n",
    "    file_list = [\n",
    "       \"TREC AP 88-90/TREC AP 88-90/Topics-requetes/topics.1-50.txt\",\n",
    "       \"TREC AP 88-90/TREC AP 88-90/Topics-requetes/topics.51-100.txt\",\n",
    "       \"TREC AP 88-90/TREC AP 88-90/Topics-requetes/topics.101-150.txt\",\n",
    "    ]\n",
    "    # Loop over the list of files\n",
    "    for filename in file_list:\n",
    "\n",
    "        # Open the .gz file\n",
    "        with open(filename, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            topic_requests_string = file.read()\n",
    "            for topic in topic_pattern.finditer(topic_requests_string):\n",
    "                topic_content = topic.group(1)\n",
    "\n",
    "                # Extracting individual elements\n",
    "                topic_id = num_pattern.search(topic_content)\n",
    "                title = title_pattern.search(topic_content)\n",
    "                desc = desc_pattern.search(topic_content)\n",
    "                \n",
    "                if(topic_id) :\n",
    "                    requests.append([topic_id.group(1), title.group(1) if title else None, desc.group(1).strip() if desc else None])\n",
    "                    \n",
    "    return requests \n",
    "\n",
    "def build_request(requests) :\n",
    "    short_requests = []\n",
    "    long_requests = []\n",
    "    for request in requests :  \n",
    "        # request[1] => title , request[2] => description\n",
    "        short_requests.append(request[1])\n",
    "        long_requests.append(request[1] + request[2])\n",
    "    return (short_requests, long_requests)\n",
    "\n",
    "from java.io import File\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.search.similarities import ClassicSimilarity, BM25Similarity, LMJelinekMercerSimilarity, BooleanSimilarity\n",
    "from org.apache.lucene.index import  DirectoryReader\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "\n",
    "def set_similirity_weight_schemat(searcher, weight_schemat) :\n",
    "    if weight_schemat == \"classic\" : \n",
    "        searcher.setSimilarity(ClassicSimilarity())\n",
    "    if weight_schemat == \"bm25\" : \n",
    "        searcher.setSimilarity(BM25Similarity(1.2,0.75))\n",
    "    if weight_schemat == \"LM\" : \n",
    "        searcher.setSimilarity(LMJelinekMercerSimilarity(0.7))\n",
    "    if weight_schemat == \"boolean\" : \n",
    "        searcher.setSimilarity(BooleanSimilarity())\n",
    "\n",
    "def get_requests_run(queries) :\n",
    "    run = []\n",
    "    for index, query_string in enumerate(queries) :\n",
    "        # Check if the query string is empty or consists of only whitespace\n",
    "        try :\n",
    "            query_string = query_string.replace(\"/\", \"\").replace(\"?\", \"\").replace(\"`\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            query = QueryParser(\"content\", analyzer).parse(query_string)\n",
    "            hits = searcher.search(query, 1000).scoreDocs\n",
    "\n",
    "            # Check if the query has any hits\n",
    "            if len(hits) == 0 :\n",
    "                print(\"No hits found for query : \", query_string)\n",
    "           \n",
    "            for i,hit in enumerate(hits):\n",
    "                doc = searcher.doc(hit.doc)\n",
    "                run.append((index+1, \"Q0\", doc.get(\"doc_id\"), i+1, hit.score, \"trec_run\"))\n",
    "        except :\n",
    "            print(\"Error in query : \", query_string)\n",
    "            continue\n",
    "    return run\n",
    "\n",
    "def write_run_file(results, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for result in results:\n",
    "            f.write(\" \".join(map(str, result)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Q0', 'AP890731-0265', 1, 11.58420181274414, 'trec_run')\n",
      "(1, 'Q0', 'AP890731-0265', 1, 19.042831420898438, 'trec_run')\n"
     ]
    }
   ],
   "source": [
    "similarity = \"LM\"\n",
    "\n",
    "queries = get_requests() \n",
    "reader = DirectoryReader.open(index)\n",
    "searcher = IndexSearcher(reader)\n",
    "set_similirity_weight_schemat(searcher, similarity)\n",
    "\n",
    "# build_request \n",
    "short_requests, long_requests = build_request(queries)\n",
    "\n",
    "short_requests_run = get_requests_run(short_requests)\n",
    "long_requests_run = get_requests_run(long_requests)\n",
    "\n",
    "print(short_requests_run[0])\n",
    "print(long_requests_run[0])\n",
    "write_run_file(short_requests_run, \"TREC AP 88-90/TREC AP 88-90/trec_runs/short_basic_\" + similarity + \".run\")\n",
    "write_run_file(long_requests_run, \"TREC AP 88-90/TREC AP 88-90/trec_runs/long_basic_\" + similarity + \".run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trec eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trectools import TrecEval, TrecQrel, TrecRun\n",
    "\n",
    "def trec_eval(run_path, qrel_path):\n",
    "    run = TrecRun(run_path)\n",
    "    qrel= TrecQrel(qrel_path)\n",
    "    te = TrecEval(run, qrel)\n",
    "\n",
    "    result = {}\n",
    "    result[\"num_ret\"] = te.get_retrieved_documents(per_query=False)\n",
    "    result[\"num_rel\"] = te.get_relevant_documents(per_query=False)\n",
    "    result[\"num_rel_ret\"] = te.get_relevant_retrieved_documents(per_query=False)\n",
    "    result[\"map\"] = te.get_map(depth=1000, per_query=False, trec_eval=True) \n",
    "    for v in [5, 10, 15, 20, 30, 100, 200, 500, 1000]:\n",
    "        result[f\"P@{v}\"] = te.get_precision(depth=v, per_query=False, trec_eval=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "def format_res(overall_result) :\n",
    "  map_values = [inner_dict['map'] for inner_dict in overall_result.values()]\n",
    "  mean_map = sum(map_values) / len(map_values)\n",
    "  P_10 = [inner_dict['P@10'] for inner_dict in overall_result.values()]\n",
    "  mean_P_10 = sum(P_10) / len(P_10)\n",
    "  # 5, 10, 15, 20, 30, 100, 200, 500, 1000\n",
    "  return { \n",
    "    \"MMAP\" : mean_map, \n",
    "    \"P@10\" :mean_P_10,\n",
    "    \"num_ret\": overall_result[\"1\"][\"num_ret\"], \n",
    "    \"num_rel\": overall_result[\"1\"][\"num_rel\"],\n",
    "    \"num_rel_ret\" : overall_result[\"1\"][\"num_rel_ret\"],\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEMME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 150000, 'num_rel': 25549, 'num_rel_ret': 12365, 'map': 0.1906649454549337, 'P@5': 0.3946666666666667, 'P@10': 0.37666666666666665, 'P@15': 0.3595555555555556, 'P@20': 0.344, 'P@30': 0.3222222222222222, 'P@100': 0.2474, 'P@200': 0.19613333333333335, 'P@500': 0.12604, 'P@1000': 0.08243333333333334}\n"
     ]
    }
   ],
   "source": [
    "long_stemme_bm25 = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/long_stemme_bm25.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(long_stemme_bm25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 150000, 'num_rel': 25549, 'num_rel_ret': 11053, 'map': 0.14909556560447088, 'P@5': 0.2946666666666667, 'P@10': 0.2873333333333333, 'P@15': 0.2782222222222222, 'P@20': 0.2676666666666667, 'P@30': 0.2597777777777778, 'P@100': 0.20713333333333334, 'P@200': 0.1663, 'P@500': 0.10836000000000001, 'P@1000': 0.07368666666666666}\n"
     ]
    }
   ],
   "source": [
    "long_stemme_classic = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/long_stemme_classic.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(long_stemme_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 150000, 'num_rel': 25549, 'num_rel_ret': 11610, 'map': 0.17500922752299103, 'P@5': 0.376, 'P@10': 0.32666666666666666, 'P@15': 0.31155555555555553, 'P@20': 0.3053333333333333, 'P@30': 0.29111111111111115, 'P@100': 0.22753333333333334, 'P@200': 0.1801, 'P@500': 0.11737333333333334, 'P@1000': 0.07739333333333334}\n"
     ]
    }
   ],
   "source": [
    "long_stemme_lm = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/long_stemme_LM.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(long_stemme_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 144288, 'num_rel': 25549, 'num_rel_ret': 11488, 'map': 0.18136221076223133, 'P@5': 0.35333333333333333, 'P@10': 0.33066666666666666, 'P@15': 0.3146666666666667, 'P@20': 0.30466666666666664, 'P@30': 0.2902222222222222, 'P@100': 0.2305333333333333, 'P@200': 0.18513333333333334, 'P@500': 0.11834666666666666, 'P@1000': 0.07658}\n"
     ]
    }
   ],
   "source": [
    "short_stemme_bm25 = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/short_stemme_bm25.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(short_stemme_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 144288, 'num_rel': 25549, 'num_rel_ret': 10397, 'map': 0.13537729488258624, 'P@5': 0.24666666666666667, 'P@10': 0.24400000000000002, 'P@15': 0.24177777777777776, 'P@20': 0.23433333333333337, 'P@30': 0.23155555555555557, 'P@100': 0.1864, 'P@200': 0.1539666666666667, 'P@500': 0.10250666666666668, 'P@1000': 0.06931333333333334}\n"
     ]
    }
   ],
   "source": [
    "short_stemme_classic = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/short_stemme_classic.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(short_stemme_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 144288, 'num_rel': 25549, 'num_rel_ret': 10977, 'map': 0.16457703092183423, 'P@5': 0.32533333333333336, 'P@10': 0.29533333333333334, 'P@15': 0.28444444444444444, 'P@20': 0.27599999999999997, 'P@30': 0.2602222222222222, 'P@100': 0.21153333333333335, 'P@200': 0.173, 'P@500': 0.11132, 'P@1000': 0.07318000000000001}\n"
     ]
    }
   ],
   "source": [
    "short_stemme_lm = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/short_stemme_LM.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(short_stemme_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 150000, 'num_rel': 25549, 'num_rel_ret': 11019, 'map': 0.1668214469130914, 'P@5': 0.38666666666666666, 'P@10': 0.3513333333333334, 'P@15': 0.3342222222222222, 'P@20': 0.3203333333333333, 'P@30': 0.2988888888888889, 'P@100': 0.22446666666666668, 'P@200': 0.17503333333333332, 'P@500': 0.11262666666666665, 'P@1000': 0.07346000000000001}\n"
     ]
    }
   ],
   "source": [
    "long_basic_bm25 = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/long_basic_bm25.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(long_basic_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 150000, 'num_rel': 25549, 'num_rel_ret': 9726, 'map': 0.12732352486635037, 'P@5': 0.27199999999999996, 'P@10': 0.26733333333333337, 'P@15': 0.26666666666666666, 'P@20': 0.25600000000000006, 'P@30': 0.24, 'P@100': 0.18420000000000003, 'P@200': 0.14673333333333333, 'P@500': 0.09694666666666668, 'P@1000': 0.06484}\n"
     ]
    }
   ],
   "source": [
    "long_basic_classic = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/long_basic_classic.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(long_basic_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 150000, 'num_rel': 25549, 'num_rel_ret': 10385, 'map': 0.14989938727803764, 'P@5': 0.3466666666666667, 'P@10': 0.31533333333333335, 'P@15': 0.3008888888888888, 'P@20': 0.28433333333333327, 'P@30': 0.26844444444444443, 'P@100': 0.205, 'P@200': 0.15983333333333336, 'P@500': 0.10476000000000002, 'P@1000': 0.06923333333333333}\n"
     ]
    }
   ],
   "source": [
    "long_basic_LM = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/long_basic_LM.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(long_basic_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 143631, 'num_rel': 25549, 'num_rel_ret': 10062, 'map': 0.15695876880382706, 'P@5': 0.33866666666666667, 'P@10': 0.31333333333333335, 'P@15': 0.29777777777777775, 'P@20': 0.285, 'P@30': 0.27, 'P@100': 0.20693333333333333, 'P@200': 0.16133333333333333, 'P@500': 0.10196000000000001, 'P@1000': 0.06708000000000001}\n"
     ]
    }
   ],
   "source": [
    "short_basic_bm25 = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/short_basic_bm25.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(short_basic_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 143631, 'num_rel': 25549, 'num_rel_ret': 9045, 'map': 0.1130943997839862, 'P@5': 0.20800000000000002, 'P@10': 0.21733333333333335, 'P@15': 0.21244444444444444, 'P@20': 0.21333333333333335, 'P@30': 0.212, 'P@100': 0.16706666666666667, 'P@200': 0.13453333333333334, 'P@500': 0.08845333333333334, 'P@1000': 0.06029333333333334}\n"
     ]
    }
   ],
   "source": [
    "short_basic_classic = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/short_basic_classic.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(short_basic_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ret': 143631, 'num_rel': 25549, 'num_rel_ret': 9435, 'map': 0.13894211367637874, 'P@5': 0.30533333333333335, 'P@10': 0.28, 'P@15': 0.26844444444444443, 'P@20': 0.25933333333333325, 'P@30': 0.2451111111111111, 'P@100': 0.19173333333333334, 'P@200': 0.15093333333333334, 'P@500': 0.09462666666666666, 'P@1000': 0.06289333333333333}\n"
     ]
    }
   ],
   "source": [
    "short_basic_LM = trec_eval(\"TREC AP 88-90/TREC AP 88-90/trec_runs/short_basic_LM.run\", \"TREC AP 88-90/TREC AP 88-90/jugements de pertinence/qrels.1-150-AP8890.txt\")\n",
    "print(short_basic_LM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
